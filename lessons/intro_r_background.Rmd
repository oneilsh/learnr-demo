## Some R Background

The R programming language has a rich history, tracing its roots to the S language originally developed for statistical computing in the mid-1970s at Bell Laboratories. Later, the open-source R project extended the capabilities of S while incorporating features of languages like LISP and Scheme.^[Some of the content in this material is sourced from the open-access book [*A Primer for Computaitonal Biology*](https://open.oregonstate.education/computationalbiology).]

It's worth mentioning that R is an 'interpreted' language, rather than a 'compiled' language. This means that R code is not translated (compiled) into bytecode that a CPU can read natively. Rather, R code is interpreted (read) by another program, called the interpreter. (The interpreter program itself *is* compiled and run by the CPU.) There are downsides to such a scheme--many types of computation run slower in R than they might if they were written in a compiled language (like C). 

Why would the designers of a programming language choose to have their program "run" by another program, when it's possible to have them run directly on the CPU? There are a number of reasons, the most important of which is flexibility. Consider the task of adding a new cool feature to R (which has happened many times over the years). If we were forced to translate all code directly to CPU-readable instructions, this would be quite a bit of work, because CPU instructions are fairly limited. On the other hand, supporting a new feature in an interpreted language is often quite easy, requiring a small change to the interpreter program (which, yes, does need to itself be re-compiled to CPU-readable code). Some examples of interpreted languages include R, Python, and JavaScript, and some examples of compiled languages include C, C++, and Go.^[Recent advancements in language design now enable languages to have the best of both worlds. Julia, for example, is a language similar to R in flexibility, but also compiles to produce very fast-running programs. Julia is not yet the data science language du jour, and it's unclear whether it will grow to the popularity enjoyed by Python and R.]

As a result of its heritage R is a remarkably flexible language. With so much flexibility comes both power and interesting ways of thinking about programming. While languages like Python emphasize the use of for-loops and if-statements to control program flow, R provides an alternative syntax for manipulation of data through sophisticated logical statements. Even though interpreted languages are generally slow, for many of the statistical tasks in which R specializes the underlying interpreter code is highly optimized or parallelized so that analyses of millions or billions of data points can be completed quickly. Like many programming languages, R supports a "package" system allowing users to easily download additional software libraries for specialized uses.

The flexibility of R has a dark side, however, compared to other more rigid languages. R lets package developers (and the core R developers) easily "invent" new syntax. Over the years different specialized syntaxes have waxed and waned in popularity, making R more of an evolving ecosystem than a static tool. Very few people know the ins and outs of all that is available in the R ecosystem. Fortunately, it's not necessary to know everything to be successful!

### Tidyverse and Base-R

"Base" R is the syntax and set of functions originally designed for R, and included in a basic installation as part of the interpreter. While powerful, many don't consider it particularly friendly, especially for newcomers.

Today the most common specialized syntax for R is provided by the 'tidyverse.' Originating in a few specialized packages providing easier-to-use functions for common operations (like subsetting rows or generating a plot from a table, known as a data frame in R), the [tidyverse](https://www.tidyverse.org/) now includes over [26 packages](https://github.com/tidyverse/tidyverse/blob/master/DESCRIPTION) with similar syntax for many kinds of data analysis. 

Here's a small code comparison. A number of datasets are included in base-R, including for example the `mtcars` data frame describing features of different automobiles 

```{r statedesc, exercise=TRUE}
mtcars
```

Suppose we want to filter this dataset to only rows where `mpg` is less than 24 and `cyl` is less than 6, and further sort by `hp`, but only show those three columns in the output. In base R we can use syntax like the following:

```{r basestateex, exercise=TRUE}
subset <- mtcars[mtcars$mpg < 24 & mtcars$cyl < 6, c("mpg", "cyl", "hp")]
subset_ordered <- subset[order(subset$hp), ]
subset_ordered
```

The `dplyr` package from the tidyverse provides a much more readable alternative, with `%>%` reading like "then":

```{r basestatextidy, exercise=TRUE}
# load the dplyr library
library(dplyr)

subset_ordered <- mtcars %>% filter(mpg < 24, cyl < 6) %>% select(mpg, cyl, hp) %>% arrange(hp)
subset_ordered
```

(The extra printed messages are warnings produced by the `library(dplyr)` line, indicating that some functionality provided by the dplyr library replaces some functionality from base-R.)

As of this writing, an ongoing debate in the R community concerns whether beginners should learn base-R first, tidyverse first, or some mix. There are pros and cons to each approach:

**Base-R First** 

*Pros*: Not all analyses can be completed entirely with tidyverse packages, and learning base-R syntax provides a foundational understanding of R. 

*Cons*: The syntax can be intimidating, and the learning curve longer, meaning it can take longer for new programmers to start producing useful results. 

**Tidyverse First**

*Pros*: Tidyverse functionality is widely used in practice, and specific concepts can be employed quickly by beginners for basic analyses. 

*Cons*: Tidyverse packages co-exist nicely with base-R, but exactly how they do so can be confusing. The collection of tidyverse packages introduce many functions with specific purposes, while base-R tends to utilize the same few, flexible concepts. 

<hr />

So, how will we approach learning R? We're likely to jump back and forth, starting with a few of the most important concepts from base-R, and introducing tidyverse alternatives along the way. As the lessons progress, we'll prefer using tidyverse when we can, but utilize base-R when we must (and occasionally just as reminders).

### Prior Experience with Python or R

If you are coming in with prior experience in R, fear not - we've designed these lessons to be reasonably quick, with exercises along the way for practice and checking understanding. We've also included sections that are more advanced, but optional, for those wishing to deepen their understanding. 

If you are coming in with prior experience in Python (or another language), we request that you keep an open mind while learning R. While the two languages are superficially similar, they differ in many significant ways. Python has long held the [philosophy](https://www.python.org/dev/peps/pep-0020/) that "there should be one-- and preferably only one --obvious way to do it." This is in contrast to R, where there are several ways to do nearly everything. Python is a mainstay in machine learning (of the less-statistical sort, e.g. deep learning) and applications where R is weaker, such as systems administration and DevOps. 

On the other hand, R provides a powerful set of tools and features that many a Pythonista has grown to love; we'll leave it to you to decide which ones.

### Summary

R is an increasingly popular ecosystem of tools specializing in data analysis. While its main competitor Python shares this feature, the breadth of tools available in R for statistical data analysis warrants discovering more about it. In these lessons we'll mix base-R concepts and popular functions from the tidyverse, with the goal of providing good exposure to foundational R concepts and a quick on-ramp to practical data analysis. 

<input type="button" onclick="window.print()" value="Print This Section" class="btn btn-info"/>



